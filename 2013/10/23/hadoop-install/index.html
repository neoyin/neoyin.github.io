<!DOCTYPE html>
<html lang>
  <head><meta name="generator" content="Hexo 3.9.0">
    
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width,user-scalable=no,initial-scale=1,minimum-scale=1,maximum-scale=1">


<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">



  <meta name="description" content="打造分布式文件系统--Hadoop配置安装">




  <meta name="keywords" content="hadoop,">





    <link rel="alternate" href="/default" title="浮生若梦">




    <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=1.1">



<link rel="canonical" href="http://yoursite.com/2013/10/23/hadoop-install/">


<meta name="description" content="(Hadoop分布式文件系统 Hadoop Distributed File System) 其相关知识就不在这里介绍了,可以直接去[http://hadoop.apache.org/](http://hadoop.apache.org/),也可以直接google 直接进入安装(Ubuntu)环节: **1.环境需求** jdk 在此不做安装说明 ssh 为建立免登录所用">
<meta name="keywords" content="hadoop">
<meta property="og:type" content="article">
<meta property="og:title" content="打造分布式文件系统--Hadoop配置安装">
<meta property="og:url" content="http://yoursite.com/2013/10/23/hadoop-install/index.html">
<meta property="og:site_name" content="浮生若梦">
<meta property="og:description" content="(Hadoop分布式文件系统 Hadoop Distributed File System) 其相关知识就不在这里介绍了,可以直接去[http://hadoop.apache.org/](http://hadoop.apache.org/),也可以直接google 直接进入安装(Ubuntu)环节: **1.环境需求** jdk 在此不做安装说明 ssh 为建立免登录所用">
<meta property="og:locale" content="cn">
<meta property="og:updated_time" content="2020-03-13T14:33:53.254Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="打造分布式文件系统--Hadoop配置安装">
<meta name="twitter:description" content="(Hadoop分布式文件系统 Hadoop Distributed File System) 其相关知识就不在这里介绍了,可以直接去[http://hadoop.apache.org/](http://hadoop.apache.org/),也可以直接google 直接进入安装(Ubuntu)环节: **1.环境需求** jdk 在此不做安装说明 ssh 为建立免登录所用">


<link rel="stylesheet" type="text/css" href="/css/style.css?v=1.1">
<link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">





<script type="text/javascript">
  var themeConfig = {
    fancybox: {
      enable: false
    },
  };
</script>




    





    





    <title> 打造分布式文件系统--Hadoop配置安装 - 浮生若梦 </title>
  </head>

  <body>
    <div id="page">
      <header id="masthead"><div class="site-header-inner">
    <h1 class="site-title">
        <a href="/." class="logo">浮生若梦</a>
    </h1>

    <nav id="nav-top">
        
            <ul id="menu-top" class="nav-top-items">
                
                    <li class="menu-item">
                        <a href="/archives">
                            
                            
                                Archives
                            
                        </a>
                    </li>
                
                    <li class="menu-item">
                        <a href="/about">
                            
                            
                                About
                            
                        </a>
                    </li>
                
                
            </ul>
        
    </nav>

</div>

      </header>
      <div id="content">
        
    <div id="primary">
        
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          打造分布式文件系统--Hadoop配置安装
        
      </h1>

      <time class="post-time">
          Oct 23 2013
      </time>
    </header>



    
            <div class="post-content">
            <p></p>
(Hadoop分布式文件系统 Hadoop Distributed File System)
其相关知识就不在这里介绍了,可以直接去[http://hadoop.apache.org/](http://hadoop.apache.org/),也可以直接google
直接进入安装(Ubuntu)环节: **1.环境需求** jdk 在此不做安装说明 ssh
为建立免登录所用 <a id="more"></a>

<pre><code>ssh-keygen -t rsa -P &quot;&quot;  #创建密钥
cd ~/.ssh
cat id_rsa.pub &gt;&gt; authorized_keys #加入授权
ssh localhost

需要在master slave 中都加入</code></pre><p><strong>2.下载安装</strong> 下载地址:<br><a href="http://hadoop.apache.org/releases.html#Download" target="_blank" rel="noopener">http://hadoop.apache.org/releases.html#Download</a><br>这里下载的版本:<br><a href="http://www.eu.apache.org/dist/hadoop/common/hadoop-2.2.0/hadoop-2.2.0.tar.gz" target="_blank" rel="noopener">hadoop-2.2.0.tar.gz</a><br>Release Notes : <a href="http://hadoop.apache.org/docs/r2.2.0/hadoop-project-dist/hadoop-common/releasenotes.html" target="_blank" rel="noopener">Hadoop 2.2.0 Release<br>Notes</a><br>解压到/usr/local 目录下</p>
<pre><code>sudo ln -s hadoop-2.2.0/ hadoop   #建立链接
添加环境路径
export HADOOP_INSTALL=/usr/local/hapood
export PATH=$HADOOP_INSTALL/bin:$HADOOP_INSTALL/sbin:$PATH
export HADOOP_MAPRED_HOME=$HADOOP_INSTALL
export HADOOP_COMMON_HOME=$HADOOP_INSTALL
export HADOOP_HDFS_HOME=$HADOOP_INSTALL
export YARN_HOME=$HADOOP_INSTALL  
cd /usr/local/hadoop
bin/hadoop version     #查看hadoop信息
输入如下安装成功:
Hadoop 2.2.0
Subversion https://svn.apache.org/repos/asf/hadoop/common -r 1529768
Compiled by hortonmu on 2013-10-07T06:28Z
Compiled with protoc 2.5.0
From source with checksum 79e53ce7994d1628b240f09af91e1af4
This command was run using /usr/local/hadoop-2.2.0/share/hadoop/common/hadoop-common-2.2.0.jar</code></pre><p><strong>3.配置</strong> 这一部分描述在节点 上安装配置Hadoop， 这里的安装是指： 安装一个<br>HDFS （包含一个命名节点 namenode和一个数据节点 datanode） 以及 一个<br>Map/Reduce 机群（带有 jobtracker 和一个单独的 tasktracker） .<br>配置过程同样适用于大规模的机群的安装。<br>此版本配置文件目录为$HADOOP_INSTALL/etc/hadoop</p>
<pre><code>hadoop-env.sh：包含Hadoop设置的一些环境变量。你可以使用他们影响Hadoop Deamons的行为，例如：日志文件的存储地点、 最大数量的堆栈内存的使用等等. 需修改的一个环境变量是JAVA_HOME
slaves ：这个文件每行列出一个HOST的信息，在这些HOST上 Hadoop slave daemons (datanodes 和 tasktrackers)运行其上. 默认是一行： localhost
core-site.xml： 此文件包含具体每个节点对所有 Hadoop daemons 和 Map/Reduce jobs的设置。此文件默认为空。
mapred-site.xml ：此文件包含具体每个节点对 Hadoop Map/Reduce daemons 和 jobs的设置信息。默认为空。

各相关配置如下:
各master slave /etc/hosts添加
#ip              $hostname
192.168.50.110  neoyin-Inspiron-580
192.168.50.124  lifeix-DX4840
192.168.50.123  abc-DX4840

core-site.xml
&lt;configuration&gt;
&lt;property&gt;
&lt;name&gt;fs.defaultFS&lt;/name&gt;
&lt;value&gt;hdfs://masterIP:9000&lt;/value&gt;
&lt;/property&gt;
&lt;/configuration&gt;

hdfs-site.xml
&lt;configuration&gt;
&lt;property&gt;
&lt;name&gt;dfs.name.dir&lt;/name&gt;
&lt;value&gt;file:/data/hdfs/name&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
&lt;name&gt;dfs.data.dir&lt;/name&gt;
&lt;value&gt;file:/data/hdfs/data&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
&lt;name&gt;dfs.permissions&lt;/name&gt;
&lt;value&gt;false&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
&lt;name&gt;dfs.replication&lt;/name&gt;
&lt;value&gt;1&lt;/value&gt;
&lt;/property&gt;
&lt;/configuration&gt;

mapred-site.xml
&lt;property&gt;
&lt;name&gt;mapreduce.framework.name&lt;/name&gt;
&lt;value&gt;yarn&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
&lt;name&gt;mapred.system.dir&lt;/name&gt;
&lt;value&gt;file:/data/hdfs/mapred/mapred/system&lt;/value&gt;
&lt;final&gt;true&lt;/final&gt;
&lt;/property&gt;
&lt;property&gt;
&lt;name&gt;mapred.local.dir&lt;/name&gt;
&lt;value&gt;file:/data/hdfs/mapred/mapred/local&lt;/value&gt;
&lt;final&gt;true&lt;/final&gt;
&lt;/property&gt;

yarn-site.xml
&lt;property&gt;
&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
&lt;value&gt;mapreduce_shuffle&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
&lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt;
&lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;
&lt;/property&gt;

master
#masterip
slave
#slave_1_ip
#slave_2_ip
...</code></pre><p>建立运行Hadoop第一<br>步是格式化Haoop文件系统，它是实现在本地机群的文件系统之上<br>，格式化文件系统是你安装Haddoop第一时间应该做的事情。不要格式化一个正在运行中的Hadoop文件系统，这会导致你所有的数据被清除。</p>
<p><strong>格 式化之前，</strong>确保 <code>dfs.name.dir</code> 目录存在。 如果你选择默认的值，那么<br><code>mkdir -p $dfs.name.dir</code> 命令即可实现 . 格式化 (其实是初始化<br><code>dfs.name.dir</code> 变量指向的路径), 运行如下命令：</p>
<pre><code>bin/hadoop namenode -format
INFO namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at xxx-xxx/127.0.1.1
************************************************************/
启动
sbin/start-all.sh
check 启动是否成功
jps命令查看如下:
14640 ResourceManager
15138 Jps
13967 NameNode
14497 SecondaryNameNode</code></pre><p>访问如下页面<a href="http://localhost:8088/" target="_blank" rel="noopener">http://localhost:8088/</a> <a href="http://localhost:50070/" target="_blank" rel="noopener">http://localhost:50070/</a><br>可查看相关信息 Notes:</p>
<ol>
<li>Master和Slave上的几个conf配置文件不需要全部同步，如果确定都是通过Master去启动和关闭，那么Slave机器上的配置不需要去维护。但如果希望在任意一台机器都可以启动和关闭Hadoop，那么就需要全部保持一致了。</li>
<li>Master和Slave机器上的<code>/etc/hosts</code>中必须把集群中机器都配置上去，就算在配置文件中使用的是IP也需如此,不然一直会出现<br>datanode denied communication with namenode 相关错误. 参考资料:</li>
</ol>
<hr>
<p>参考：</p>
<ul>
<li><a href="http://hadoop.apache.org/docs/r2.2.0/" target="_blank" rel="noopener">http://hadoop.apache.org/docs/r2.2.0/</a></li>
<li><a href="http://dongxicheng.org/mapreduce-nextgen/hadoop-2-2-0/" target="_blank" rel="noopener">http://dongxicheng.org/mapreduce-nextgen/hadoop-2-2-0/</a></li>
<li><a href="http://www.yongbok.net/blog/how-to-install-hadoop-2-2-0-pseudo-distributed-mode/" target="_blank" rel="noopener">http://www.yongbok.net/blog/how-to-install-hadoop-2-2-0-pseudo-distributed-mode/</a></li>
<li><a href="http://www.cnblogs.com/xia520pi/category/346943.html" target="_blank" rel="noopener">http://www.cnblogs.com/xia520pi/category/346943.html</a></li>
</ul>

            </div>
          

    
      <footer class="post-footer">
        <div class="post-tags">
          
            <a href="/tags/hadoop/">hadoop</a>
          
        </div>

        
        
  <nav class="post-nav">
    
      <a class="prev" href="/2013/10/26/open-vpn/">
        <i class="iconfont icon-left"></i>
        <span class="prev-text nav-default">Ubuntu中搭建Open-vpn服务器</span>
        <span class="prev-text nav-mobile">Prev</span>
      </a>
    
    
      <a class="next" href="/2013/10/19/nginx-install/">
        <span class="next-text nav-default">nginx 安装</span>
        <span class="prev-text nav-mobile">Next</span>
        <i class="iconfont icon-right"></i>
      </a>
    
  </nav>

        
  <div class="comments" id="comments">
    
  </div>


      </footer>
    
  </article>

    </div>

      </div>

      <footer id="colophon"><span class="copyright-year">
    
        &copy;
    
        2012 -
    
    2020
    <span class="footer-author">Neo.</span>
    <span class="power-by">
        Powered by <a class="hexo-link" href="https://hexo.io/">Hexo</a>
    </span>
</span>

      </footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div>
    


    


    




  
    <script type="text/javascript" src="/lib/jquery/jquery-3.1.1.min.js"></script>
  

  

    <script type="text/javascript" src="/js/src/theme.js?v=1.1"></script>
<script type="text/javascript" src="/js/src/bootstrap.js?v=1.1"></script>

    

  
  <script type="application/ld+json">
  {
  "@context": "http://www.schema.org",
  "@type": "Person",
  "@id": "https://huangyijie.com/about/",
  "name": "黄奕杰",
  "alternateName": "Henry Huang",
  "nationality": "中国",
  "birthPlace" : {
    "@type": "Place",
      "address": {
        "@type": "PostalAddress",
      "addressLocality": "汕头市",
      "addressRegion": "广东省",
          "addressCountry": "中国"
    }
  },
  "gender": "Male",
  "Description": "Software Engineer",
  "disambiguatingDescription": "Full stack software engineer, focus on Java and JavaScript.",
  "jobTitle": "Software Engineer",
  "url": "https://huangyijie.com",
  "image": "https://s.gravatar.com/avatar/4e0e61fdf1b2bcfb4ee31da27601fe6b?s=512&r=g",
  "address": {
    "@type": "PostalAddress",
    "addressLocality": "深圳市",
    "addressRegion": "广东省",
    "addressCountry": "中国"
  },
  "sameAs": [
    "http://weibo.com/626242034",
    "https://github.com/henryhuang",
    "https://unsplash.com/@henryhh"
    ]
  }
  </script>
  </body>
</html>
