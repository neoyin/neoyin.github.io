<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="Neo"><title>打造分布式文件系统--HDFS · 浮生若梦</title><meta name="description" content="经过打造分布式文件系统–Hadoop配置安装我们已简单的搭建了hadoop
但分布式文件系统之路才刚刚开始呢.这一旅程的第一步就是HDFS
关于其介绍网上太多,而且基本类似,就不在这里阐述了.大家自行搜索
http://www.cnblogs.com/forfuture1978/archive/20"><meta name="keywords"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="short icon" href="/images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/blog_basic.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"></head><body><div class="sidebar animated fadeInDown"><div class="logo-title"><div class="title"><img src="/images/logo@2x.png" style="width:127px;"><h3 title><a href="/">浮生若梦</a></h3></div></div><ul class="social-links"></ul><div class="footer"><a target="_blank" href="/"><span>Theme by </span></a><a href="https://www.caicai.me"> CaiCai </a><span>&</span><a href="https://github.com/Ben02/hexo-theme-Anatole"> Ben</a><div class="by_farbox"><a href="https://hexo.io/zh-cn/" target="_blank">Proudly published with Hexo&#65281;</a></div></div></div><div class="main"><div class="page-top animated fadeInDown"><div class="nav"><li><a href="/">首页</a></li><li><a href="/about">关于</a></li><li><a href="/archives">归档</a></li><li><a href="/links">友链</a></li></div><div class="information"><div class="back_btn"><li><a class="fa fa-chevron-left" onclick="window.history.go(-1)"> </a></li></div><div class="avatar"><img></div></div></div><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post animated fadeInDown"><div class="post-title"><h3><a>打造分布式文件系统--HDFS</a></h3></div><div class="post-content"><p>经过<br><a href="http://www.floatinglife.cn/distributed-hadoop" target="_blank" rel="noopener">打造分布式文件系统–Hadoop配置安装</a><br>我们已简单的搭建了hadoop</p>
<p>但分布式文件系统之路才刚刚开始呢.这一旅程的第一步就是HDFS</p>
<p>关于其介绍网上太多,而且基本类似,就不在这里阐述了.大家自行搜索</p>
<p><a href="http://www.cnblogs.com/forfuture1978/archive/2010/03/14/1685351.html" target="_blank" rel="noopener">http://www.cnblogs.com/forfuture1978/archive/2010/03/14/1685351.html</a></p>
<p>Hadoop的命令行提供了一套完整命令接口，就像Linux命令一样方便使用。</p>
<p>如下:</p>
<pre><code>bin/hadoop dfs
DEPRECATED: Use of this script to execute hdfs command is deprecated.
Instead use the hdfs command for it.

Usage: hadoop fs [generic options]
    [-appendToFile ...]
    [-cat [-ignoreCrc] ...]
    [-checksum ...]
    [-chgrp [-R] GROUP PATH...]
    [-chmod [-R] &lt;MODE[,MODE]... | OCTALMODE&gt; PATH...]
    [-chown [-R] [OWNER][:[GROUP]] PATH...]
    [-copyFromLocal [-f] [-p] ...]
    [-copyToLocal [-p] [-ignoreCrc] [-crc] ...]
    [-count [-q] ...]
    [-cp [-f] [-p] ...]
    [-createSnapshot []]
    [-deleteSnapshot]
    [-df [-h] [ ...]]
    [-du [-s] [-h] ...]
    [-expunge]
    [-get [-p] [-ignoreCrc] [-crc] ...]
    [-getmerge [-nl]]
    [-help [cmd ...]]
    [-ls [-d] [-h] [-R] [ ...]]
    [-mkdir [-p] ...]
    [-moveFromLocal ...]
    [-moveToLocal]
    [-mv ...]
    [-put [-f] [-p] ...]
    [-renameSnapshot]
    [-rm [-f] [-r|-R] [-skipTrash] ...]
    [-rmdir [--ignore-fail-on-non-empty]

Generic options supported are
-conf &lt;configuration file&gt; specify an application configuration file
-D &lt;property=value&gt; use value for given property
-fs &lt;local|namenode:port&gt; specify a namenode
-jt &lt;local|jobtracker:port&gt; specify a job tracker
-files &lt;comma separated list of files&gt; specify comma separated files to be copied to the map reduce cluster
-libjars &lt;comma separated list of jars&gt; specify comma separated jar files to include in the classpath.
-archives &lt;comma separated list of archives&gt; specify comma separated archives to be unarchived on the compute machines</code></pre><p>在这里可查看<br><a href="http://hadoop.apache.org/docs/r2.2.0/hadoop-project-dist/hadoop-common/FileSystemShell.html#expunge" target="_blank" rel="noopener">http://hadoop.apache.org/docs/r2.2.0/hadoop-project-dist/hadoop-common/FileSystemShell.html#expunge</a></p>
<a id="more"></a>

<p>不做过多演示,直接进入java API 环节</p>
<p>由于之前hadoop 版本为2.2 所以我们需要引入hadoop-client相对应版本.</p>
<p>在maven 项目pom.xml文件中添加相关仓库</p>
<pre><code>&lt;repositories&gt;
&lt;repository&gt;
&lt;id&gt;cloudera-repo-releases&lt;/id&gt;
&lt;url&gt;https://repository.cloudera.com/artifactory/repo/&lt;/url&gt;
&lt;/repository&gt;
&lt;/repositories&gt;

项目依赖中添加
&lt;dependency&gt;
&lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;
&lt;artifactId&gt;hadoop-client&lt;/artifactId&gt;
&lt;version&gt;2.2.0-cdh5.0.0-beta-1&lt;/version&gt;
&lt;/dependency&gt;</code></pre><p>代码示例:</p>
<pre><code>    /**
 * 创建目录
 * @param dir
 * @throws IOException
 */
public static void mkdirs(String dir) throws IOException{
    Path path = new Path(hdfs+dir);
    FileSystem fs = FileSystem.get(URI.create(hdfs),conf);
    if (!fs.exists(path)) {
        fs.mkdirs(path);
    }else {

    }
    fs.close();
}
//删除
public static void rmDir(String dir) throws IOException{
    Path path = new Path(hdfs+dir);
    FileSystem fs = FileSystem.get(URI.create(hdfs),conf);
    fs.deleteOnExit(path);
    fs.close();
}
//显示
public static void cat(String file) throws IOException{
    Path path = new Path(file);
    FileSystem fs = FileSystem.get(URI.create(hdfs), conf);
    FSDataInputStream fsdis = null;
    System.out.println(&quot;cat: &quot; + file);
    try {
        fsdis = fs.open(path);
        IOUtils.copyBytes(fsdis, System.out, 4096, false);
    } finally {
        IOUtils.closeStream(fsdis);
        fs.close();
    }
}

//从本地copy
public static void upload() throws IOException{
    String path =&quot;/home/neoyin/Desktop/testtest&quot;;
    String fpath =hdfs+&quot;ttt&quot;;
    InputStream in = new BufferedInputStream(new FileInputStream(path));
    FileSystem fs = FileSystem.get(URI.create(fpath),conf);
    OutputStream out =fs.create(new Path(fpath),new Progressable() {
        @Override
        public void progress() {
            System.out.println(&quot;===&quot;);
        }
    });
    IOUtils.copyBytes(in, out, 4096, true);
}</code></pre><p>以上只是通过简单java API 去了解并简单应用hadoop .</p>
<p>执行上述程序可以在<a href="http://localhost:50070/" target="_blank" rel="noopener">http://$master_ip:50070</a><br>查看文件的创建等是否正确</p>
<hr>
<p>参考:</p>
<ul>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/03/14/1685351.html" target="_blank" rel="noopener">http://www.cnblogs.com/forfuture1978/archive/2010/03/14/1685351.html</a></li>
<li><a href="http://www.cnblogs.com/xia520pi/archive/2012/05/28/2520813.html" target="_blank" rel="noopener">http://www.cnblogs.com/xia520pi/archive/2012/05/28/2520813.html</a></li>
<li><a href="http://blog.fens.me/hadoop-hdfs-api/" target="_blank" rel="noopener">http://blog.fens.me/hadoop-hdfs-api/</a></li>
</ul>
</div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2013-10-30</span><i class="fa fa-tag"></i><a class="tag" href="/categories/技术流/" title="技术流">技术流 </a><a class="tag" href="/tags/hadoop/" title="hadoop">hadoop </a></div></div></div></div><div class="share"><div class="evernote"><a class="fa fa-bookmark" href="javascript:(function(){EN_CLIP_HOST='http://www.evernote.com';try{var%20x=document.createElement('SCRIPT');x.type='text/javascript';x.src=EN_CLIP_HOST+'/public/bookmarkClipper.js?'+(new%20Date().getTime()/100000);document.getElementsByTagName('head')[0].appendChild(x);}catch(e){location.href=EN_CLIP_HOST+'/clip.action?url='+encodeURIComponent(location.href)+'&amp;title='+encodeURIComponent(document.title);}})();" ref="nofollow" target="_blank"></a></div><div class="weibo"><a class="fa fa-weibo" href="javascript:void((function(s,d,e){try{}catch(e){}var f='http://service.weibo.com/share/share.php?',u=d.location.href,p=['url=',e(u),'&amp;title=',e(d.title),'&amp;appkey=2924220432'].join('');function a(){if(!window.open([f,p].join(''),'mb',['toolbar=0,status=0,resizable=1,width=620,height=450,left=',(s.width-620)/2,',top=',(s.height-450)/2].join('')))u.href=[f,p].join('');};if(/Firefox/.test(navigator.userAgent)){setTimeout(a,0)}else{a()}})(screen,document,encodeURIComponent));"></a></div><div class="twitter"><a class="fa fa-twitter" href="http://twitter.com/home?status=,http://yoursite.com/2013/10/30/hadoop-hdfs/,浮生若梦,打造分布式文件系统--HDFS,;"></a></div></div><div class="pagination"><ul class="clearfix"><li class="pre pagbuttons"><a class="btn" role="navigation" href="/2013/10/31/what-if-facebook-of-the-dead/" title="【What if 系列】Facebook之死亡国">上一篇</a></li><li class="next pagbuttons"><a class="btn" role="navigation" href="/2013/10/28/mahout-sample/" title="mahout入门示例">下一篇</a></li></ul></div></div></div></div></div><script src="/js/jquery.js"></script><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script></body></html>