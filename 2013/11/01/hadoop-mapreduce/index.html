<!DOCTYPE html>
<html lang>
  <head><meta name="generator" content="Hexo 3.9.0">
    
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width,user-scalable=no,initial-scale=1,minimum-scale=1,maximum-scale=1">


<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">



  <meta name="description" content="打造分布式文件系统-Mapreduce">




  <meta name="keywords" content="hadoop,">





    <link rel="alternate" href="/default" title="浮生若梦">




    <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=1.1">



<link rel="canonical" href="http://yoursite.com/2013/11/01/hadoop-mapreduce/">


<meta name="description" content="前面进行了Hadoop配置安装 以及了解了HDFS 接下来就是Mapreduce了.其概念就是Map（映射）Reduce（化简）主要思想，都是从函数式编程语言里借来的，以及从矢量编程语言里借来的特性.">
<meta name="keywords" content="hadoop">
<meta property="og:type" content="article">
<meta property="og:title" content="打造分布式文件系统-Mapreduce">
<meta property="og:url" content="http://yoursite.com/2013/11/01/hadoop-mapreduce/index.html">
<meta property="og:site_name" content="浮生若梦">
<meta property="og:description" content="前面进行了Hadoop配置安装 以及了解了HDFS 接下来就是Mapreduce了.其概念就是Map（映射）Reduce（化简）主要思想，都是从函数式编程语言里借来的，以及从矢量编程语言里借来的特性.">
<meta property="og:locale" content="cn">
<meta property="og:updated_time" content="2020-03-13T10:06:01.928Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="打造分布式文件系统-Mapreduce">
<meta name="twitter:description" content="前面进行了Hadoop配置安装 以及了解了HDFS 接下来就是Mapreduce了.其概念就是Map（映射）Reduce（化简）主要思想，都是从函数式编程语言里借来的，以及从矢量编程语言里借来的特性.">


<link rel="stylesheet" type="text/css" href="/css/style.css?v=1.1">
<link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">





<script type="text/javascript">
  var themeConfig = {
    fancybox: {
      enable: false
    },
  };
</script>




    





    





    <title> 打造分布式文件系统-Mapreduce - 浮生若梦 </title>
  </head>

  <body>
    <div id="page">
      <header id="masthead"><div class="site-header-inner">
    <h1 class="site-title">
        <a href="/." class="logo">浮生若梦</a>
    </h1>

    <nav id="nav-top">
        
            <ul id="menu-top" class="nav-top-items">
                
                    <li class="menu-item">
                        <a href="/archives">
                            
                            
                                Archives
                            
                        </a>
                    </li>
                
                    <li class="menu-item">
                        <a href="/about">
                            
                            
                                About
                            
                        </a>
                    </li>
                
                
            </ul>
        
    </nav>

</div>

      </header>
      <div id="content">
        
    <div id="primary">
        
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          打造分布式文件系统-Mapreduce
        
      </h1>

      <time class="post-time">
          Nov 1 2013
      </time>
    </header>



    
            <div class="post-content">
            <p>前面进行了<a href="http://www.floatinglife.cn/hadoop-install" target="_blank" rel="noopener">Hadoop配置安装</a></p>
<p>以及了解了<a href="http://www.floatinglife.cn/hadoop-hdfs" target="_blank" rel="noopener">HDFS</a></p>
<p>接下来就是Mapreduce了.其概念就是Map（映射）Reduce（化简）主要思想，都是从函数式编程语言里借来的，以及从矢量编程语言里借来的特性.</p>
<a id="more"></a>

<p>相关的原理咱先忽略,直接进入实例应用.</p>
<p>从hadoop源码中hadoop-2.2.0-src/hadoop-mapreduce-project/hadoop-mapreduce-examples/<br>打开其示例程序WordCount如下:</p>
<pre><code>public class WordCount {

  public static class TokenizerMapper 
       extends Mapper&lt;Object, Text, Text, IntWritable&gt;{

    private final static IntWritable one = new IntWritable(1);
    private Text word = new Text();

    public void map(Object key, Text value, Context context
                    ) throws IOException, InterruptedException {
      StringTokenizer itr = new StringTokenizer(value.toString());
      while (itr.hasMoreTokens()) {
        word.set(itr.nextToken());
        context.write(word, one);
      }
    }
  }

  public static class IntSumReducer 
       extends Reducer&lt;Text,IntWritable,Text,IntWritable&gt; {
    private IntWritable result = new IntWritable();

    public void reduce(Text key, Iterable values, 
                       Context context
                       ) throws IOException, InterruptedException {
      int sum = 0;
      for (IntWritable val : values) {
        sum += val.get();
      }
      result.set(sum);
      context.write(key, result);
    }
  }

  public static void main(String[] args) throws Exception {
    Configuration conf = new Configuration();
    String[] otherArgs = new GenericOptionsParser(conf, args).getRemainingArgs();
    if (otherArgs.length != 2) {
      System.err.println(&quot;Usage: wordcount  &quot;);
      System.exit(2);
    }
    Job job = new Job(conf, &quot;word count&quot;);
    job.setJarByClass(WordCount.class);
    job.setMapperClass(TokenizerMapper.class);
    job.setCombinerClass(IntSumReducer.class);
    job.setReducerClass(IntSumReducer.class);
    job.setOutputKeyClass(Text.class);
    job.setOutputValueClass(IntWritable.class);
    FileInputFormat.addInputPath(job, new Path(otherArgs[0]));
    FileOutputFormat.setOutputPath(job, new Path(otherArgs[1]));
    System.exit(job.waitForCompletion(true) ? 0 : 1);
  }
}</code></pre><p>分为三步:</p>
<ol>
<li>TokenizerMapper 类实现 Mapper 接口中的 map 方法，输入参数中的 value<br>是文本文件中的一行</li>
<li>IntSumReducer类实现 Reducer 接口中的 reduce 方法, 输入参数中的 key,<br>values 是由 Map 任务输出的中间结果，values 是一个 Iterator, 遍历这个<br>Iterator, 就可以得到属于同一个 key 的所有 value. 此处，key<br>是一个单词，value 是词频。只需要将所有的 value<br>相加，就可以得到这个单词的总的出现次数。</li>
<li>配置 Job并运行</li>
</ol>
<p>就这么简单的三步,实现了分布式统计一批文本文件中单词出现的频率的功能.</p>
<p><a name="table1"></a><strong>JobConf 常用可定制参数</strong></p>
<table summary="JobConf 常用可定制参数" width="100%" border="0" cellspacing="0" cellpadding="0">
<tbody>
<tr>
<th scope="col">
参数

</th>
<th scope="col">
作用

</th>
<th scope="col">
缺省值

</th>
<th scope="col">
其它实现

</th>
</tr>
<tr>
<th scope="row">
**InputFormat**

</th>
<td>
将输入的数据集切割成小数据集 InputSplits, 每一个 InputSplit 将由一个
Mapper 负责处理。此外 InputFormat 中还提供一个 RecordReader 的实现,
将一个 InputSplit 解析成 <key,value\> 对提供给 map 函数。

</key,value\></td>
<td>
TextInputFormat  
(针对文本文件，按行将文本文件切割成 InputSplits, 并用 LineRecordReader
将 InputSplit 解析成 <key,value\> 对，key 是行在文件中的位置，value
是文件中的一行)

</key,value\></td>
<td>
SequenceFileInputFormat

</td>
</tr>
<tr>
<th scope="row">
**OutputFormat**

</th>
<td>
提供一个 RecordWriter 的实现，负责输出最终结果

</td>
<td>
TextOutputFormat  
(用 LineRecordWriter 将最终结果写成纯文件文件,每个 <key,value\>
对一行，key 和 value 之间用 tab 分隔)

</key,value\></td>
<td>
SequenceFileOutputFormat

</td>
</tr>
<tr>
<th scope="row">
**OutputKeyClass**

</th>
<td>
输出的最终结果中 key 的类型

</td>
<td>
LongWritable

</td>
<td>
</td>
</tr>
<tr>
<th scope="row">
**OutputValueClass**

</th>
<td>
输出的最终结果中 value 的类型

</td>
<td>
Text

</td>
<td>
</td>
</tr>
<tr>
<th scope="row">
**MapperClass**

</th>
<td>
Mapper 类，实现 map 函数，完成输入的 <key,value\> 到中间结果的映射

</key,value\></td>
<td>
IdentityMapper  
(将输入的 <key,value\> 原封不动的输出为中间结果)

</key,value\></td>
<td>
LongSumReducer,  
LogRegexMapper,  
InverseMapper

</td>
</tr>
<tr>
<th scope="row">
**CombinerClass**

</th>
<td>
实现 combine 函数，将中间结果中的重复 key 做合并

</td>
<td>
null  
(不对中间结果中的重复 key 做合并)

</td>
<td>
</td>
</tr>
<tr>
<th scope="row">
**ReducerClass**

</th>
<td>
Reducer 类，实现 reduce 函数，对中间结果做合并，形成最终结果

</td>
<td>
IdentityReducer  
(将中间结果直接输出为最终结果)

</td>
<td>
AccumulatingReducer, LongSumReducer

</td>
</tr>
<tr>
<th scope="row">
**InputPath**

</th>
<td>
设定 job 的输入目录, job 运行时会处理输入目录下的所有文件

</td>
<td>
null

</td>
<td>
</td>
</tr>
<tr>
<th scope="row">
**OutputPath**

</th>
<td>
设定 job 的输出目录，job 的最终结果会写入输出目录下

</td>
<td>
null

</td>
<td>
</td>
</tr>
<tr>
<th scope="row">
**MapOutputKeyClass**

</th>
<td>
设定 map 函数输出的中间结果中 key 的类型

</td>
<td>
如果用户没有设定的话，使用 OutputKeyClass

</td>
<td>
</td>
</tr>
<tr>
<th scope="row">
**MapOutputValueClass**

</th>
<td>
设定 map 函数输出的中间结果中 value 的类型

</td>
<td>
如果用户没有设定的话，使用 OutputValuesClass

</td>
<td>
</td>
</tr>
<tr>
<th scope="row">
**OutputKeyComparator**

</th>
<td>
对结果中的 key 进行排序时的使用的比较器

</td>
<td>
WritableComparable

</td>
<td>
</td>
</tr>
<tr>
<th scope="row">
**PartitionerClass**

</th>
<td>
对中间结果的 key 排序后，用此 Partition 函数将其划分为R份,每份由一个
Reducer 负责处理。

</td>
<td>
HashPartitioner  
(使用 Hash 函数做 partition)

</td>
<td>
KeyFieldBasedPartitioner PipesPartitioner

</td>
</tr>
</tbody>
</table>

<p>咱们以后再研究其内部实现及原理</p>
<hr>
<p>参考资料:</p>
<p><a href="http://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop2/" target="_blank" rel="noopener">http://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop2/</a></p>
<p><a href="http://www.infoq.com/cn/articles/MapReduce-Best-Practice-1" target="_blank" rel="noopener">http://www.infoq.com/cn/articles/MapReduce-Best-Practice-1</a></p>
<p><a href="http://hadoop.apache.org/docs/r0.19.1/cn/mapred_tutorial.html#%E7%9B%AE%E7%9A%84" target="_blank" rel="noopener">http://hadoop.apache.org/docs/r0.19.1/cn/mapred_tutorial.html#%E7%9B%AE%E7%9A%84</a></p>
<p><a href="http://www.cnblogs.com/xia520pi/archive/2012/06/04/2534533.html" target="_blank" rel="noopener">http://www.cnblogs.com/xia520pi/archive/2012/06/04/2534533.html</a></p>
<p><a href="http://blog.csdn.net/kauu/article/details/1815353" target="_blank" rel="noopener">http://blog.csdn.net/kauu/article/details/1815353</a></p>
<p><a href="http://sishuok.com/forum/blogPost/list/0/5965.html" target="_blank" rel="noopener">http://sishuok.com/forum/blogPost/list/0/5965.html</a></p>

            </div>
          

    
      <footer class="post-footer">
        <div class="post-tags">
          
            <a href="/tags/hadoop/">hadoop</a>
          
        </div>

        
        
  <nav class="post-nav">
    
      <a class="prev" href="/2013/11/01/mongodb-shell-options/">
        <i class="iconfont icon-left"></i>
        <span class="prev-text nav-default">mongodb  shell 操作</span>
        <span class="prev-text nav-mobile">Prev</span>
      </a>
    
    
      <a class="next" href="/2013/10/30/hadoop-hdfs/">
        <span class="next-text nav-default">打造分布式文件系统--HDFS</span>
        <span class="prev-text nav-mobile">Next</span>
        <i class="iconfont icon-right"></i>
      </a>
    
  </nav>

        
  <div class="comments" id="comments">
    
  </div>


      </footer>
    
  </article>

    </div>

      </div>

      <footer id="colophon"><span class="copyright-year">
    
        &copy;
    
        2012 -
    
    2020
    <span class="footer-author">Neo.</span>
    <span class="power-by">
        Powered by <a class="hexo-link" href="https://hexo.io/">Hexo</a>
    </span>
</span>

      </footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div>
    


    


    




  
    <script type="text/javascript" src="/lib/jquery/jquery-3.1.1.min.js"></script>
  

  

    <script type="text/javascript" src="/js/src/theme.js?v=1.1"></script>
<script type="text/javascript" src="/js/src/bootstrap.js?v=1.1"></script>

    

  
  <script type="application/ld+json">
  {
  "@context": "http://www.schema.org",
  "@type": "Person",
  "@id": "https://huangyijie.com/about/",
  "name": "黄奕杰",
  "alternateName": "Henry Huang",
  "nationality": "中国",
  "birthPlace" : {
    "@type": "Place",
      "address": {
        "@type": "PostalAddress",
      "addressLocality": "汕头市",
      "addressRegion": "广东省",
          "addressCountry": "中国"
    }
  },
  "gender": "Male",
  "Description": "Software Engineer",
  "disambiguatingDescription": "Full stack software engineer, focus on Java and JavaScript.",
  "jobTitle": "Software Engineer",
  "url": "https://huangyijie.com",
  "image": "https://s.gravatar.com/avatar/4e0e61fdf1b2bcfb4ee31da27601fe6b?s=512&r=g",
  "address": {
    "@type": "PostalAddress",
    "addressLocality": "深圳市",
    "addressRegion": "广东省",
    "addressCountry": "中国"
  },
  "sameAs": [
    "http://weibo.com/626242034",
    "https://github.com/henryhuang",
    "https://unsplash.com/@henryhh"
    ]
  }
  </script>
  </body>
</html>
